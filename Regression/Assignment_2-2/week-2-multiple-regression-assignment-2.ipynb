{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load house sales data (train and test databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dnames_list = [\"id\",\"date\",\"price\",\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"condition\",\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"zipcode\",\"lat\",\"long\",\"sqft_living15\",\"sqft_lot15\"]\n",
    "# Data types\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, \n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, \n",
    "              'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, \n",
    "              'sqft_lot':int, 'view':int}\n",
    "\n",
    "train_datafile = 'kc_house_train_data.csv'\n",
    "train_data = pd.read_csv(train_datafile, dtype=dtype_dict)\n",
    "\n",
    "test_datafile = 'kc_house_test_data.csv'\n",
    "test_data = pd.read_csv(test_datafile, dtype=dtype_dict)\n",
    "\n",
    "sales_datafile = 'kc_house_data.csv'\n",
    "sales_data = pd.read_csv(sales_datafile, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_df, features, output):\n",
    "    \"\"\"Accepts a dataframe of data, a list of features, and a single output, and returns an initialized features matrix and output array.\n",
    "    \n",
    "    :inputs:\n",
    "    data_df - a dataframe of data\n",
    "    features - a list of features, each referring to a column in data\n",
    "    output - a single name referring to a column in data\n",
    "    \n",
    "    :return:\n",
    "    features_matrix - \n",
    "    output_array - \n",
    "    \"\"\"\n",
    "    \n",
    "    # Take data_df slice and convert to np.array\n",
    "    features_matrix = data_df[features].as_matrix()\n",
    "    \n",
    "    # Add constant as first column\n",
    "    # Make the const first and the nhstack with features_matrix\n",
    "    const = np.ones((features_matrix.shape[0], 1))\n",
    "    features_matrix = np.hstack((const, features_matrix))\n",
    "\n",
    "    # Extract output_array\n",
    "    output_array = np.array(data_df[output])\n",
    "    \n",
    "    return features_matrix, output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    \"\"\"Accepts a feature matrix of size NxD and weight vector of size Dx1 and returns the Nx1 vector of predictions.\n",
    "    \"\"\"\n",
    "    return np.dot(feature_matrix, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    \"\"\"Returns the derivative of a single input feature as an array an array of prediction error\n",
    "    NOTE: DOES NOT accept the entire feature matrix, only a single column (???) \"\"\"\n",
    "    return 2 * np.dot(feature, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance, iter_max = 10000, debug=False):\n",
    "    \"\"\"Uses gradient descent to calculate the weights for the feature_matrix given the specified outputs\"\"\"\n",
    "    converged = False\n",
    "    weights = np.asarray(initial_weights, dtype=np.float64)\n",
    "    iterations = 0\n",
    "    print(\"Starting iterations\")\n",
    "\n",
    "    while not converged and iterations < iter_max:\n",
    "        # junk = input(\"Iteration {}\".format(iterations))\n",
    "        print(\"iter: {}\".format(iterations))\n",
    "        iterations += 1\n",
    "\n",
    "        # Compute predictions\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        if debug:\n",
    "            print(\"Predictions:\")\n",
    "            print(\"Feature matrix: \")\n",
    "            pprint.pprint(feature_matrix)\n",
    "            print(\"weights\")\n",
    "            pprint.pprint(weights)\n",
    "            print(\"->predictions: {}\".format(predictions))\n",
    "\n",
    "        # Compute errors (predictions - output)\n",
    "        errors = predictions - output\n",
    "        if debug:\n",
    "            print(\"errors     : {}\".format(errors))\n",
    "\n",
    "        gradient_sum_squares = 0  # Initialize the gradient\n",
    "        # Update the weights individually (could do this as a whole faster)\n",
    "        for i in range(len(weights)):\n",
    "            if debug:\n",
    "                print(\"i: {}\".format(i))\n",
    "            # feature[:,i] is the feature column associated with weight i\n",
    "            # Compute derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "            if debug:\n",
    "                print(\"\\tderivative: {}\".format(derivative))\n",
    "\n",
    "            # Add the squared derivative to the gradient magnitude\n",
    "            gradient_sum_squares += derivative * derivative\n",
    "\n",
    "            # Update the weight based on step size and derivative\n",
    "            # I think added because there should have been a negative somewhere\n",
    "            # already(?)\n",
    "            weights[i] -= step_size * derivative\n",
    "            if debug:\n",
    "                print(\"\\tweight[i]: {}\".format(weights[i]))\n",
    "\n",
    "        gradient_magnitude = math.sqrt(gradient_sum_squares)\n",
    "        if debug:\n",
    "            print(gradient_magnitude)\n",
    "\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the regression_gradient_descent function on some actual data. In particular we will\n",
    "use the gradient descent to estimate the model from Week 1 using just an intercept and slope. Use the\n",
    "following parameters:\n",
    "* features: ‘sqft_living’\n",
    "* output: ‘price’\n",
    "* initial weights: -47000, 1 (intercept, sqft_living respectively)\n",
    "* step_size = 7e-12\n",
    "* tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "output='price'\n",
    "initial_weights = [-47000., 1.]\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "iter_max = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterations\n",
      "iter: 0\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n"
     ]
    }
   ],
   "source": [
    "# Get the features matrix and outputs for the simple feature list\n",
    "simple_features_matrix, output_array = get_numpy_data(train_data, simple_features, output)\n",
    "\n",
    "# Calculate the feature weights given this feature matrix/output\n",
    "simple_weights = regression_gradient_descent(simple_features_matrix, output_array, initial_weights, step_size, tolerance, iter_max, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 9. Quiz Question: What is the value of the weight for sqft_living -- the second element of\n",
    "‘simple_weights’ (rounded to 1 decimal place)? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for sqft_living using TRAIN data = 281.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight for sqft_living using TRAIN data = {:.1f}\".format(simple_weights[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a corresponding ‘test_simple_feature_matrix’ and ‘test_output’ using test_data. Using\n",
    "‘test_simple_feature_matrix’ and ‘simple_weights’ compute the predicted house prices on all the test\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the test_simple_feature_matrix and test_output_array, then use the above simple_weights (from training) to predict \n",
    "# the values\n",
    "test_simple_features_matrix, test_output_array = get_numpy_data(test_data, simple_features, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question: What is the predicted price for the 1st house in the Test data set for model 1\n",
    "(round to nearest dollar)? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not run the regression again because we use the weights from the TRAINING database and apply those to the features_matrix from the TEST database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the first house in the TEST data set using the simple model = $356134\n"
     ]
    }
   ],
   "source": [
    "test_simple_predictions = predict_outcome(test_simple_features_matrix, simple_weights) # See note above for use\n",
    "print(\"The price of the first house in the TEST data set using the simple model = ${:.0f}\".format(test_simple_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute RSS on all test data for this model. Record the value and store it for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_RSS(true_outcome, prediction):\n",
    "    return ((true_outcome - prediction) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RSS for the test data using the simple model = 275400044902128.3\n"
     ]
    }
   ],
   "source": [
    "test_simple_RSS = get_RSS(test_output_array, test_simple_predictions)\n",
    "print(\"The RSS for the test data using the simple model = {}\".format(test_simple_RSS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the gradient descent to get a model with more than 1 predictor variable (and an\n",
    "intercept). Use the following parameters:\n",
    "* model features = ‘sqft_living’, ‘sqft_living_15’\n",
    "* output = ‘price’\n",
    "* initial weights = [-100000, 1, 1] (intercept, sqft_living, and sqft_living_15 respectively)\n",
    "* step size = 4e-12\n",
    "* tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['sqft_living', 'sqft_living15']\n",
    "output='price'\n",
    "initial_weights = [-100000., 1., 1.]\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9\n",
    "iter_max = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterations\n",
      "iter: 0\n",
      "iter: 1\n",
      "iter: 2\n",
      "iter: 3\n",
      "iter: 4\n",
      "iter: 5\n",
      "iter: 6\n",
      "iter: 7\n",
      "iter: 8\n",
      "iter: 9\n",
      "iter: 10\n",
      "iter: 11\n",
      "iter: 12\n",
      "iter: 13\n",
      "iter: 14\n",
      "iter: 15\n",
      "iter: 16\n",
      "iter: 17\n",
      "iter: 18\n",
      "iter: 19\n",
      "iter: 20\n",
      "iter: 21\n",
      "iter: 22\n",
      "iter: 23\n",
      "iter: 24\n",
      "iter: 25\n",
      "iter: 26\n",
      "iter: 27\n",
      "iter: 28\n",
      "iter: 29\n",
      "iter: 30\n",
      "iter: 31\n",
      "iter: 32\n",
      "iter: 33\n",
      "iter: 34\n",
      "iter: 35\n",
      "iter: 36\n",
      "iter: 37\n",
      "iter: 38\n",
      "iter: 39\n",
      "iter: 40\n",
      "iter: 41\n",
      "iter: 42\n",
      "iter: 43\n",
      "iter: 44\n",
      "iter: 45\n",
      "iter: 46\n",
      "iter: 47\n",
      "iter: 48\n",
      "iter: 49\n",
      "iter: 50\n",
      "iter: 51\n",
      "iter: 52\n",
      "iter: 53\n",
      "iter: 54\n",
      "iter: 55\n",
      "iter: 56\n",
      "iter: 57\n",
      "iter: 58\n",
      "iter: 59\n",
      "iter: 60\n",
      "iter: 61\n",
      "iter: 62\n",
      "iter: 63\n",
      "iter: 64\n",
      "iter: 65\n",
      "iter: 66\n",
      "iter: 67\n",
      "iter: 68\n",
      "iter: 69\n",
      "iter: 70\n",
      "iter: 71\n",
      "iter: 72\n",
      "iter: 73\n",
      "iter: 74\n",
      "iter: 75\n",
      "iter: 76\n",
      "iter: 77\n",
      "iter: 78\n",
      "iter: 79\n",
      "iter: 80\n",
      "iter: 81\n",
      "iter: 82\n",
      "iter: 83\n",
      "iter: 84\n",
      "iter: 85\n",
      "iter: 86\n",
      "iter: 87\n",
      "iter: 88\n",
      "iter: 89\n",
      "iter: 90\n",
      "iter: 91\n",
      "iter: 92\n",
      "iter: 93\n",
      "iter: 94\n",
      "iter: 95\n",
      "iter: 96\n",
      "iter: 97\n",
      "iter: 98\n",
      "iter: 99\n",
      "iter: 100\n",
      "iter: 101\n",
      "iter: 102\n",
      "iter: 103\n",
      "iter: 104\n",
      "iter: 105\n",
      "iter: 106\n",
      "iter: 107\n",
      "iter: 108\n",
      "iter: 109\n",
      "iter: 110\n",
      "iter: 111\n",
      "iter: 112\n",
      "iter: 113\n",
      "iter: 114\n",
      "iter: 115\n",
      "iter: 116\n",
      "iter: 117\n",
      "iter: 118\n",
      "iter: 119\n",
      "iter: 120\n",
      "iter: 121\n",
      "iter: 122\n",
      "iter: 123\n",
      "iter: 124\n",
      "iter: 125\n",
      "iter: 126\n",
      "iter: 127\n",
      "iter: 128\n",
      "iter: 129\n",
      "iter: 130\n",
      "iter: 131\n",
      "iter: 132\n",
      "iter: 133\n",
      "iter: 134\n",
      "iter: 135\n",
      "iter: 136\n",
      "iter: 137\n",
      "iter: 138\n",
      "iter: 139\n",
      "iter: 140\n",
      "iter: 141\n",
      "iter: 142\n",
      "iter: 143\n",
      "iter: 144\n",
      "iter: 145\n",
      "iter: 146\n",
      "iter: 147\n",
      "iter: 148\n",
      "iter: 149\n",
      "iter: 150\n",
      "iter: 151\n",
      "iter: 152\n",
      "iter: 153\n",
      "iter: 154\n",
      "iter: 155\n",
      "iter: 156\n",
      "iter: 157\n",
      "iter: 158\n",
      "iter: 159\n",
      "iter: 160\n",
      "iter: 161\n",
      "iter: 162\n",
      "iter: 163\n",
      "iter: 164\n",
      "iter: 165\n",
      "iter: 166\n",
      "iter: 167\n",
      "iter: 168\n",
      "iter: 169\n",
      "iter: 170\n",
      "iter: 171\n",
      "iter: 172\n",
      "iter: 173\n",
      "iter: 174\n",
      "iter: 175\n",
      "iter: 176\n",
      "iter: 177\n",
      "iter: 178\n",
      "iter: 179\n",
      "iter: 180\n",
      "iter: 181\n",
      "iter: 182\n",
      "iter: 183\n",
      "iter: 184\n",
      "iter: 185\n",
      "iter: 186\n",
      "iter: 187\n",
      "iter: 188\n",
      "iter: 189\n",
      "iter: 190\n",
      "iter: 191\n",
      "iter: 192\n",
      "iter: 193\n",
      "iter: 194\n",
      "iter: 195\n",
      "iter: 196\n",
      "iter: 197\n",
      "iter: 198\n",
      "iter: 199\n",
      "iter: 200\n",
      "iter: 201\n",
      "iter: 202\n",
      "iter: 203\n",
      "iter: 204\n",
      "iter: 205\n",
      "iter: 206\n",
      "iter: 207\n",
      "iter: 208\n",
      "iter: 209\n",
      "iter: 210\n",
      "iter: 211\n",
      "iter: 212\n",
      "iter: 213\n",
      "iter: 214\n",
      "iter: 215\n",
      "iter: 216\n",
      "iter: 217\n",
      "iter: 218\n",
      "iter: 219\n",
      "iter: 220\n",
      "iter: 221\n",
      "iter: 222\n",
      "iter: 223\n",
      "iter: 224\n",
      "iter: 225\n",
      "iter: 226\n",
      "iter: 227\n",
      "iter: 228\n",
      "iter: 229\n",
      "iter: 230\n",
      "iter: 231\n",
      "iter: 232\n",
      "iter: 233\n",
      "iter: 234\n",
      "iter: 235\n",
      "iter: 236\n",
      "iter: 237\n",
      "iter: 238\n",
      "iter: 239\n",
      "iter: 240\n",
      "iter: 241\n",
      "iter: 242\n",
      "iter: 243\n",
      "iter: 244\n",
      "iter: 245\n",
      "iter: 246\n",
      "iter: 247\n",
      "iter: 248\n",
      "iter: 249\n",
      "iter: 250\n",
      "iter: 251\n",
      "iter: 252\n",
      "iter: 253\n",
      "iter: 254\n",
      "iter: 255\n",
      "iter: 256\n",
      "iter: 257\n",
      "iter: 258\n",
      "iter: 259\n",
      "iter: 260\n",
      "iter: 261\n",
      "iter: 262\n",
      "iter: 263\n",
      "iter: 264\n",
      "iter: 265\n",
      "iter: 266\n",
      "iter: 267\n",
      "iter: 268\n",
      "iter: 269\n",
      "iter: 270\n",
      "iter: 271\n",
      "iter: 272\n",
      "iter: 273\n"
     ]
    }
   ],
   "source": [
    "features_matrix, output_array = get_numpy_data(train_data, features, output)\n",
    "weights = regression_gradient_descent(features_matrix, output_array, initial_weights, step_size, tolerance, iter_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.99999688e+04,   2.45072603e+02,   6.52795267e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the regression weights from this second model (using sqft_living and sqft_living_15) and predict\n",
    "the outcome of all the house prices on the TEST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 15. Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2\n",
    "(round to nearest dollar)? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the test_simple_feature_matrix and test_output_array, then use the above simple_weights (from training) to predict \n",
    "# the values\n",
    "test_features_matrix, test_output_array = get_numpy_data(test_data, features, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of the first house in the TEST data set using the more advanced model = $366651\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_outcome(test_features_matrix, weights)\n",
    "print(\"The price of the first house in the TEST data set using the more advanced model = ${:.0f}\".format(test_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 17. Quiz Question: Which estimate was closer to the true price for the 1st house on the TEST data\n",
    "set, model 1 or model 2? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected price = 310000.0, model 1 price = 356134.4432550024, model 2 price = 366651.4116294939\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected price = {}, model 1 price = {}, model 2 price = {}\".format(test_output_array[0], test_simple_predictions[0], test_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 19. Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RSS for the test data using the simple model = 270263443629803.56\n",
      "RSS for model 2 is less than that for model 1\n"
     ]
    }
   ],
   "source": [
    "test_RSS = get_RSS(test_output_array, test_predictions)\n",
    "print(\"The RSS for the test data using the simple model = {}\".format(test_RSS))\n",
    "print(\"RSS for model 2 is less than that for model 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes\n",
    "* The calculation of the intercept using gradient descent was REALLY bad - the constant basically didn't change throughout the iterations.  I THINK this is a problem with the method, not the implementation, as I compared to another person's implementation and found similar results.  Looking through the future assignments I think there might be some better methods added in later.\n",
    "* I think the iterative gradient descent could also be replaced with a matrix solver, couldn't it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
